

## Introduction

In the increasingly digitized world, applications in a wide varity of domains are shifting to harness the ability to process, understand, and exploit data collected from different sources. Deep learning-based methods, in particularly, have recently empowered many applications to leveraging their data. This incluses examples from customer-centric applications, such as personalized recommendations, online advertising, search engines and interest/intention modeling from customers’ behavior. In these applications, leveraging deep learning tools can significantly enhance the user's experience while increasing revenues. Data generated in customer-centric applications and other critical real-world domains such as health and medicine, biology, business, industrial engineering, _etc_ are often high-dimensional, sparse and imbalanced. These adverse data properties challenge the application of deep learning in real-world applications due to the fact that they can cause poor model performance, failed projects, and potentially serious social implications.

The complexities explored here are different from many traditional deep learning applications, such as image classification and speech recorgnition, which have rich, dense datasets for model development and testing. Typical prediction tasks related to click-through rates, for example, involve billions of sparse features. Thus, the question of how to mine, model and perform inference on such data is a challenging and interesting problem. The characteristics  of high-dimensional, sparse and imbalanced data pose unique challenges to the adoption of deep learning, and requires the community to re-assess the traditional methodologies and explore novel domain-specific approaches to learn and evaluate robust and trustworthy model. This workshop will provide a venue for researchers and practicioners to discuss challenges, opportunities, and new ideas related to the application of deep learning on high-dimensional, sparse, and imbalanced data. 

These challenges have been widely studied by the traditional machine learning and data mining community, and new techniques have been developed for deep learning. These include methods such as transfer learning, few-shot learning, meta-learning, active learning, data resampling, data generation and augmentation, one-class learning, domain decompositions, etc.. Through the course of this workshop, we will drill into the latest challenges and methodologies whilst reflecting on what the traditional machine learning and data mining researchers can contribute to the advancement of state-of-the-art in deep learning from high-dimensional, sparse, and imbalanced data with adverse properties. The workshop will bring together a diverse cross-section of speakers and a wide community of data mining and deep learning researchers and practitioners from academia, industry, and government.


## Previous Editions

Website for dlp-kdd2021 can be found **[<b style="color:red"> here </b>](https://dlp-kdd.github.io/)**

Website for s2d-olad2021 can be found **[<b style="color:red"> here </b>](https://s2d-olad.github.io/)**



## Important Dates

- Submission deadline:  May 26, 2022 23:59 anywhere on earth
- Acceptance notification: June 20 2022.
- Workshop date: August 15, 2022   


## Topics of Interest
<!-- Topics include but are not limited to topics related to deep learning with high-dimensional, sparse and imbalanced data, large scale deep learning training framework, high-performance online inference engine or toolkits that help breaking the black box of deep learning models, such as -->
The topics of interest include, but are not limited to, the following:
- Challenges and Risks of deep learning from high-dimensional, sparse, and imbalanced data
- Large scale user response prediction modeling
- Representation learning for high-dimensional, sparse, and imbalanced data
- Multi-domain generalization through few-shot learning and zero-shot learning
- Embedding techniques, manifold learning and dictionary learning
- Scalable, distributed and parallel training system for deep learning
- High-throughput and low-latency real-time serving systems
- Applications of transfer learning and meta-learning for high-dimensional, sparse, and imbalanced data
- Understanding user behavior
- Large-scale recommendation and retrieval systems
- Model compression for industrial applications 
- Auto-machine learning, auto-feature selection
- Explainable deep learning for high-dimensional, sparse, and imbalanced data
- Data augmentation and anomaly detection for high-dimensional, sparse, and imbalanced data
- Generative Adversarial Networks for high-dimensional, sparse, and imbalanced data
- Leveraging insights from traditional machine learning and data mining approaches for deep learning with high-dimensional, sparse, and imbalanced data
- Moral and social issues related to the applications of models trained on high-dimensional, sparse, and imbalanced data
- Other challenges encountered in real-world applications



## Key Dates and Author Instructions

Please format your papers using the standard KDD 2022 style files. Submissions must be in PDF format and formatted according to the new [Standard ACM Conference Proceedings Template](https://www.acm.org/publications/proceedings-template).

In addition to full-length papers (up to 9 pages) describing clear research advances, we encourage the submission of short papers (2-4 pages) that discuss work in progress, new challenges and limitations, and future directions for representations learning to overcome limited and adverse data, along with socially relevant problems, ethical AI and AI safety.

Submissions should be anonymized. 

A link to the paper submission system will be provided shortly.

## Selection Criteria

All submissions will undergo peer review by the workshop’s program committee. Accepted papers will be chosen based on technical merit, empirical validation, novelty, and suitability to the workshop’s goals.

The workshop aims to provide an engaging platform for dialog that will push the state-of-the-art in deep learning from high-dimensional, sparse, and imbalanced data. To this end, selected papers will include long papers, short works-in-progress, novel topics and future directions. Work that has already appeared or is scheduled to appear in a journal, workshop, or conference (including KDD 2022) must be significantly extended to be eligible for workshop submission. Work that is currently under review at another venue may be submitted.

If you have any questions about submissions or our workshop, please contact [*dlpkddworkshop@gmail.com*](mailto:dlpkddworkshop@gmail.com)

## Workshop Chairs


<div class="photo">
  <a href="http://byeah.github.io">
  <img src="assets/img/jby.jpeg" class="shake shake-little" />
  </a><br />
  <a href="http://byeah.github.io">Biye Jiang</a>
  <div>Algorithm expert of advertising group</div>
  <div>Alibaba</div>
</div>

<div class="photo">
  <a href="https://www.american.edu/cas/faculty/rcorizzo.cfm">
  <img src="assets/img/roberto.jpg" class="shake shake-little">
  </a><br>
  <a href="https://www.american.edu/cas/faculty/rcorizzo.cfm">Roberto Corizzo</a>
  <div>Assistant Professor</div>
  <div>American University, Washington D.C., USA</div>
  <div>rcorizzo@american.edu</div>
</div>

<div class="photo">
  <a href="https://scholar.google.com/citations?user=eUMnOc0AAAAJ&amp;hl=en">
  <img src="assets/img/zxq.jpeg" class="shake shake-little" />
  </a><br />
  <a href="https://scholar.google.com/citations?user=eUMnOc0AAAAJ&amp;hl=en">Xiaoqiang Zhu</a>
  <div>Tech Lead of advertising group</div>
  <div>Alibaba</div>
</div>
    
<div class="photo">
  <a href="https://web.cs.dal.ca/~bellinger/">
  <img src="assets/img/cb.jpeg" class="shake shake-little">
  </a><br>
  <a href="https://web.cs.dal.ca/~bellinger/">Colin Bellinger</a>
  <div>AI Researcher</div>
  <div>National Research Council of Canada</div>
  <div>colin.bellinger@nrc-cnrc.gc.ca</div>
</div>

<div class="photo">
  <a href="https://scholar.google.com/citations?user=r9JOIloAAAAJ&amp;hl=en">
  <img src="assets/img/lkc.jpeg" class="shake shake-little" />
  </a><br />
   <a href="https://scholar.google.com/citations?user=r9JOIloAAAAJ&amp;hl=en">Kuang-chih Lee</a>
  <div>Tech Lead of business intelligence group, AliExpress</div>
  </div>
  
  
<div class="photo">
  <a href="https://paobranco.github.io">
  <img src="assets/img/paula.jpg" class="shake shake-little">
  </a><br>
  <a href="hhttps://paobranco.github.io">Paula Branco</a>
  <div>Assistant Professor</div>
  <div>University of Ottawa, Ottawa, Canada</div>
  <div>pbranco@uottawa.ca</div>
</div>
  

<div class="photo">
  <a href="https://scholar.google.com/citations?user=n_E0Bg4AAAAJ&amp;hl=en">
  <img src="assets/img/zgr.jpeg" class="shake shake-little" />
  </a><br />
<a href="https://scholar.google.com/citations?user=n_E0Bg4AAAAJ&amp;hl=en">Guorui Zhou</a>
  <div>Senior Algorithm expert of advertising group</div>
  <div>Alibaba</div>
  </div>

<div class="photo">
  <a href="https://www.american.edu/cas/faculty/japkowic.cfm">
  <img src="assets/img/nathalie.jpeg" class="shake shake-little">
  </a><br>
  <a href="https://www.american.edu/cas/faculty/japkowic.cfm">Nathalie Japkowicz</a>
  <div>Professor</div>
  <div>American University, Washington D.C., USA</div>
  <div>japkowic@american.edu</div>
</div>

<div class="photo">
  <a href="http://wzhe.me/">
    <img src="assets/img/wz.jpg" class="shake shake-little" />
  </a><br />
  <a href="http://wzhe.me/">Zhe Wang</a>
  <div>Tech Lead</div>
  <div>Recommendation group, Roku</div>
  </div>

<div class="photo">
  <a href="http://www.saying.ren/">
    <img src="assets/img/rk.jpg" class="shake shake-little" />
  </a><br />
  <a href="http://www.saying.ren/">Kan Ren</a>
  <div>Microsoft Research</div>
  </div>

<div class="photo">
  <a href="http://ir.aiqingyao.org/home">
    <img src="assets/img/aqy.jpg" class="shake shake-little" />
  </a><br />
  <a href="http://ir.aiqingyao.org/home">Qingyao Ai</a>
  <div>Assistant Professor</div>
  <div>University of Utah</div>
  </div>

<div class="photo">
  <a href="http://wnzhang.net">
    <img src="assets/img/zwn.png" class="shake shake-little" />
  </a><br />
  <a href="http://wnzhang.net">Weinan Zhang</a>
  <div>Associate Professor</div>
  <div>Shanghai Jiao Tong University</div>
  </div>

<div class="photo">
</div>
  
<div class="photo">
  <a href="https://scholar.google.com/citations?user=fUtHww0AAAAJ&amp;hl=en">
    <img src="assets/img/trm.jpeg" class="shake shake-little" />
  </a><br />
  <a href="https://scholar.google.com/citations?user=fUtHww0AAAAJ&amp;hl=en">Ruiming Tang</a>
  <div>Senior Researcher</div>
  <div>Huawei Noah Ark Lab</div>
  </div>
  
<div class="photo">
</div>

## Program Committee
To be defined. 

## Sponsor
To be defined. 
