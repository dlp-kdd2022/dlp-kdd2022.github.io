

## Introduction

In the increasingly digitalized world, it is of utmost importance for various applications to harness the ability to process, understand, and exploit data collected from the Internet. For instance, in customer-centric applications such as personalized recommendation, online advertising, and search engines, interest/intention modeling from customersâ€™ behavioral data can not only significantly enhance user experiences but also greatly contribute to revenues. Recently, we have witnessed that Deep Learning-based approaches began to empower these internet- scale applications by better leveraging the massive data. However, the data in these internet-scale applications are high dimensional and extremely sparse, which makes it different from many applications with dense data such as image classification and speech recognition where Deep Learning-based approaches have been extensively studied. For example, the training samples of a typical click-through rate (CTR) prediction task often involve billions of sparse features, how to mine, model and inference from such data becomes an interesting problem, and how to leverage such data in Deep Learning could be a new research direction. The characteristics of such data pose unique challenges to the adoption of Deep Learning in these applications, including modeling, training, and online serving, etc. More and more communities from both academia and industry have initiated the endeavors to solve these challenges. This workshop will provide a venue for both the research and engineering communities to discuss the challenges, opportunities, and new ideas in the practice of Deep Learning on high-dimensional sparse data.

Questions of interest include (but are not limited to):

- What are the challenges and risks associated with deep representation learning from limited and adverse data?
- How do the challenges and required solutions overlap and diverge in deep and shallow representation learning? Can old insights be repurposed for the deep world?
- What are the most pertinent questions related to deep representation learning from data with adverse properties? Questions to consider are: is it possible to generalize few-shot learning across domains? What are the relative advantages of few-shot learning over fine-tuned transfer learning? What are the impacts of, and solutions to, deep representation learning from long-tailed data and data with imbalanced class priors? Moreover, we welcome, and in fact, encourage other questions.
- What are the moral and social issues related to the applications of models trained on limited and adverse data? Can these be mitigated with new technical solutions?



Website for dlp-kdd2021 can be found **[<b style="color:red"> here </b>](https://dlp-kdd.github.io/)**

Website for s2d-olad2021 can be found **[<b style="color:red"> here </b>](https://s2d-olad.github.io/)**



## Important Dates

- Submission deadline:  May 26, 2022 23:59 anywhere on earth (Could be extended)
- Acceptance notification: June 20 2022.
- Workshop date: August 15, 2022   


## Topics of Interest
Topics include but are not limited to deep learning based network architecture design, large scale deep learning training framework, high-performance online inference engine or toolkits that help breaking the black box of deep learning models, such as
- Large Scale User Response Prediction Modeling
- Representation Learning for High-dimensional Sparse Data
- Embedding techniques, manifold learning and dictionary learning
- User Behaviour Understanding
- Large Scale Recommendation and Retrieval System
- Model compression for industrial application
- Scalable, Distributed and Parallel Training System for Deep Learning
- High throughput and low latency real time Serving System
- Applications of transfer learning, meta learning for sparse data
- Auto Machine Learning, Auto feature selection
- Explainable deep learning for high dimensional data
- Data augmentation, Anomaly Detection for High-dimensional Sparse data
- Generative Adversarial Network for sparse data
- Other challenges encountered in real-world applications

## Call for papers

Official call for papers page is [https://easychair.org/cfp/dlpkdd2021](https://easychair.org/cfp/dlpkdd2021)

Submissions are invited on describing innovative research on real-world data systems and applications, industrial experiences and identification of challenges that deploy research ideas in practical applications. Work-in-progress papers are also encouraged.

Full-length papers (up to 9 pages) or extended abstracts (2-4 pages) are welcome. Submissions must be in PDF format and formatted according to the new [Standard ACM Conference Proceedings Template](https://www.acm.org/publications/proceedings-template).

Reviews are not double-blind, and author names and affiliations should be listed. Please use the KDD official guidelines to format your paper.

All submissions can be made through EasyChair using the following link: [https://easychair.org/conferences/?conf=dlpkdd2021](https://easychair.org/conferences/?conf=dlpkdd2021) 

For all the accepted paper, we provide the option that it **could be archived in ACM Digtal Library**. You may see the publication of our first workshop at [https://dl.acm.org/doi/proceedings/10.1145/3326937](https://dl.acm.org/doi/proceedings/10.1145/3326937)


If you have any questions about submissions or our workshop, please contact [*dlpkddworkshop@gmail.com*](mailto:dlpkddworkshop@gmail.com)

## Workshop Chairs
<div class="row">
  <div class="column">
  <div class="photo">
  <a href="https://scholar.google.com/citations?user=eUMnOc0AAAAJ&hl=en">
  <img src="assets/img/zxq.png" class="shake shake-little">
  </a><br>
  <a href="https://scholar.google.com/citations?user=eUMnOc0AAAAJ&hl=en">Xiaoqiang Zhu</a>
  <div>Tech Lead of advertising group</div>
  <div>Alibaba</div>
  </div>
  </div>
  
  <div class="column">
  <div class="photo">
  <a href="https://www.american.edu/cas/faculty/japkowic.cfm">
  <img src="assets/img/nathalie.jpeg" class="shake shake-little">
  </a><br>
  <a href="https://www.american.edu/cas/faculty/japkowic.cfm">Nathalie Japkowicz</a>
  <div>Professor</div>
  <div>American University, Washington D.C., USA</div>
  <div>japkowic@american.edu</div>
  </div>
  </div>
    
  <div class="column">
  <div class="photo">
  <a href="https://paobranco.github.io">
  <img src="assets/img/paula.jpg" class="shake shake-little",width="50" height="100">
  </a><br>
  <a href="hhttps://paobranco.github.io">Paula Branco</a>
  <div>Assistant Professor</div>
  <div>University of Ottawa, Ottawa, Canada</div>
  <div>pbranco@uottawa.ca</div>
  </div>
  </div>
  </div>
<div class="row">    
  <div class="column">
  <div class="photo">
  <a href="https://www.american.edu/cas/faculty/rcorizzo.cfm">
  <img src="assets/img/roberto.jpg" class="shake shake-little",width="50" height="100">
  </a><br>
  <a href="https://www.american.edu/cas/faculty/rcorizzo.cfm">Roberto Corizzo</a>
  <div>Assistant Professor</div>
  <div>American University, Washington D.C., USA</div>
  <div>rcorizzo@american.edu</div>
  </div>
  </div>
    
  <div class="column">
  <div class="photo">
  <a href="https://web.cs.dal.ca/~bellinger/">
  <img src="assets/img/cb.jpeg" class="shake shake-little",width="50" height="100">
  </a><br>
  <a href="https://web.cs.dal.ca/~bellinger/">Colin Bellinger</a>
  <div>AI Researcher</div>
  <div>National Research Council of Canada</div>
  <div>colin.bellinger@nrc-cnrc.gc.ca</div>
  </div>
  </div>
</div>

## Program Committee

## Sponsor
